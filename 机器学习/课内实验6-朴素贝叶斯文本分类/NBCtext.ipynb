{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier for Text Classification\n",
    "- 朴素贝叶斯分类运用到的两个关键定义：条件独立假设和贝叶斯定理\n",
    "- 本实验分别运用伯努利朴素贝叶斯和多项式朴素贝叶斯的方法分类\n",
    "- 可参考网页 https://www.jianshu.com/p/b6cadf53b8b8 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification\n",
    "- Input: document D\n",
    "- Output: the predicted class C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words \n",
    "- In this task, we use BOW to represent documents, either frequency or boolean variable\n",
    "- Use frequency as feature:<img src='frequency.png'>\n",
    "- Use boolean variable as feature:<img src='boolean.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通常我们选取文本中具有代表性的部分词语来描述文本\n",
    "\n",
    "# 根据已有的数据集，取出部分如下词语组成词典，其余词语用'UNKNOWN'表示\n",
    "vocabulary = ['love', 'wonderful', 'best', 'great', 'superb', 'still', 'beautiful', \n",
    "              'bad', 'worst', 'stupid', 'waste', 'boring','UNKNOWN']\n",
    "\n",
    "# 分词，将大段文本的各词语分隔开形成列表\n",
    "def text_parse(big_string):\n",
    "    list_of_tokens = re.split(r'\\W',big_string)  \n",
    "    return [tok.lower() for tok in list_of_tokens if len(tok) > 2] \n",
    "\n",
    "\n",
    "########################## Question 1 ########################## \n",
    "\n",
    "#分别补充完整transfer(fileDj, vocabulary)和transfer_bern(fileDj, vocabulary)函数\n",
    "#tranfer将文本表示为以frequency计数的向量，transfer_bern将文本表示为以0或1计数的向量\n",
    "#其中fileDj是单个文本经由函数text_parse拆分后的词的列表，返回值BOWDj为单个文本的向量表示\n",
    "#对于vocabulary中的单词love,需将其loves,loving,loved三种形式统一转换为love\n",
    "#注：这两个函数将用在下文的数据处理中，可先查看Data Loading部分帮助理解\n",
    "\n",
    "############################################################### \n",
    "\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def transfer(fileDj, vocabulary):\n",
    "    BOWDj = [0] * len(vocabulary)\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    ##################### Start For Your Code ##################### \n",
    "    for word in fileDj:\n",
    "        stemmed_word = stemmer.stem(word)\n",
    "        if stemmed_word in vocabulary:\n",
    "            index = vocabulary.index(stemmed_word)\n",
    "            BOWDj[index] += 1\n",
    "    #####################  End For Your Code  ##################### \n",
    "\n",
    "    return BOWDj\n",
    "\n",
    "def transfer_bern(fileDj, vocabulary):\n",
    "    BOWDj = [0] * len(vocabulary)\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    ##################### Start For Your Code ##################### \n",
    "    for word in fileDj:\n",
    "        stemmed_word = stemmer.stem(word)\n",
    "        if stemmed_word in vocabulary:\n",
    "            index = vocabulary.index(stemmed_word)\n",
    "            BOWDj[index] = 1\n",
    "    #####################  End For Your Code  ##################### \n",
    "            \n",
    "    return BOWDj\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "- Loading training and testing data respectively\n",
    "- You can look up the data in `data_sets_naive_bayes/data_sets` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以测试集为例展示数据集\n",
      "\n",
      "Using frequency as feature:\n",
      "\n",
      "[[1 0 4 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 2 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [3 0 1 ... 0 0 0]]\n",
      "Using boolean variable as feature:\n",
      "\n",
      "[[1 0 1 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]]\n",
      "label:\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# 用于存储经text_parse处理后的所有文本\n",
    "doc_train = []\n",
    "doc_test = []\n",
    "\n",
    "# 用于存储经transfer处理后的所有文本\n",
    "vec_train = []\n",
    "vec_test = []\n",
    "\n",
    "# 用于存储经transfer_bern处理后的所有文本\n",
    "vec_train_bern = []\n",
    "vec_test_bern = []\n",
    "\n",
    "# 用于存储类别\n",
    "y_train = []\n",
    "y_test = []\n",
    "\n",
    "# 分别读取训练集和测试集中好评和差评文件的路径\n",
    "path1 = 'data_sets_naive_bayes/data_sets/training_set/pos'\n",
    "path2 = 'data_sets_naive_bayes/data_sets/training_set/neg'\n",
    "path3 = 'data_sets_naive_bayes/data_sets/test_set/pos'\n",
    "path4 = 'data_sets_naive_bayes/data_sets/test_set/neg'\n",
    "\n",
    "# 读取训练集\n",
    "\n",
    "file_list1 = os.listdir(path1)\n",
    "\n",
    "for file in file_list1:\n",
    "    fo = open(path1 + '/' + file, encoding='utf-8', mode='r')\n",
    "    wordlist = text_parse(fo.read())\n",
    "    doc_train.append(wordlist)\n",
    "    y_train.append(1)\n",
    "    \n",
    "file_list2 = os.listdir(path2)\n",
    "\n",
    "for file in file_list2:\n",
    "    fo = open(path2 + '/' + file, encoding='utf-8', mode='r')\n",
    "    wordlist = text_parse(fo.read())\n",
    "    doc_train.append(wordlist)\n",
    "    y_train.append(0)\n",
    "    \n",
    "# 用等长向量来表示文本    \n",
    "for doc in doc_train:\n",
    "    vec_train_bern.append(transfer_bern(doc,vocabulary))\n",
    "    vec_train.append(transfer(doc,vocabulary))\n",
    "\n",
    "    \n",
    "# 读取测试集\n",
    "\n",
    "file_list3 = os.listdir(path3)\n",
    "\n",
    "for file in file_list3:\n",
    "    fo = open(path3 + '/' + file, encoding='utf-8', mode='r')\n",
    "    wordlist = text_parse(fo.read())\n",
    "    doc_test.append(wordlist)\n",
    "    y_test.append(1)\n",
    "    \n",
    "file_list4 = os.listdir(path4)\n",
    "\n",
    "for file in file_list4:\n",
    "    fo = open(path4 + '/' + file, encoding='utf-8', mode='r')\n",
    "    wordlist = text_parse(fo.read())\n",
    "    doc_test.append(wordlist)\n",
    "    y_test.append(0)\n",
    "\n",
    "# 用等长向量来表示文本\n",
    "for doc in doc_test:\n",
    "    vec_test_bern.append(transfer_bern(doc,vocabulary))\n",
    "    vec_test.append(transfer(doc,vocabulary))\n",
    "    \n",
    "# 将数据集转化为ndarray\n",
    "# 训练集\n",
    "train_data = np.array(vec_train)\n",
    "train_data_bern = np.array(vec_train_bern)\n",
    "train_label = np.array(y_train)\n",
    "# 测试集\n",
    "test_data = np.array(vec_test)\n",
    "test_data_bern = np.array(vec_test_bern)\n",
    "test_label = np.array(y_test)\n",
    "print('以测试集为例展示数据集\\n')\n",
    "print('Using frequency as feature:\\n')\n",
    "print(test_data)\n",
    "print('Using boolean variable as feature:\\n')\n",
    "print(test_data_bern)\n",
    "print('label:')\n",
    "print(test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial vs Multivariate Bernoulli Naive Bayes Classifier\n",
    "- 已知贝叶斯公式：\n",
    "$$ P(c|d)=\\frac{P(c)P(d|c)}{p(d)}\\propto P(c)P(d|c)$$\n",
    "- 因此，要求最大的$P(c_i|d)$进而得到类别，应求出：\n",
    "$$argmaxP(c_i)P(d|c_i)$$\n",
    "- 在Multivariate Bernoulli Naive Bayes Classifier中，使用boolean variable：\n",
    "$$P(D=d|C=c_i)=P(W_1=true,W_2=false,...,W_k=true|C=c_i)$$\n",
    "- 在Multinomial Naive Bayes Classifier中，使用frequency：\n",
    "$$P(D=d|C=c_i)=P(W_1=n_1,W_2=n_2,...,W_k=n_k|C=c_i)$$\n",
    "- 其中$c$代表类别，$d$代表文件，$W_i$代表词典中的词语"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BNBC\n",
    "- 条件独立假设(naive)\n",
    "$$ P(D|C)=P(W_1,W_2,...,W_k|C)=P(W_1|C)P(W_2|C)...P(W_k|C) $$\n",
    "\n",
    "- 因此取对数后：\n",
    "$$ c=argmax\\{logP(c_j)+\\sum logp(w_i|c_j)\\} $$\n",
    "- 其中$w_i$表示$W_i$的取值\n",
    "- 在本数据集中\n",
    "$$P(c=1)=P(c=0)=\\frac{1}{2}$$\n",
    "- 因此需求出$p(w_i|c_j)$的值，给分子分母添加一个常数以smoothing\n",
    "$$P(w_i=true|c_j)=\\frac{files\\ which\\ include\\ x_i\\ and\\ are\\ in\\ class\\ c_j+1}{files\\ are\\ in\\ class\\ c_j+2}$$\n",
    "$$P(w_i=false|c_j)=1-P(w_i=true|c_j)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thetaPosTrue = [0.44017094 0.0014245  0.5042735  0.42877493 0.06552707 0.37179487\n",
      " 0.0014245  0.26495726 0.04558405 0.03988604 0.0014245  0.0014245\n",
      " 0.0014245 ]\n",
      "thetaNegTrue = [0.35754986 0.0014245  0.36324786 0.26923077 0.01851852 0.33475783\n",
      " 0.0014245  0.5042735  0.19230769 0.18233618 0.0014245  0.0014245\n",
      " 0.0014245 ]\n",
      "--------------------\n",
      "BNBC classification accuracy = 0.67\n"
     ]
    }
   ],
   "source": [
    "########################## Question 2 ########################## \n",
    "\n",
    "#利用上述公式补充完整naiveBayesBernFeature_test(Xtest, ytest, thetaPosTrue, thetaNegTrue)函数\n",
    "#得到预测值和准确率\n",
    "#naiveBayesBernFeature_train(Xtrain, ytrain)已经分别求出P(w_i=true|0)和P(w_i=true|1)\n",
    "\n",
    "############################################################### \n",
    "\n",
    "# 分别求出P(w_i=true|0)和P(w_i=true|1)\n",
    "def naiveBayesBernFeature_train(Xtrain, ytrain): \n",
    "    \n",
    "    length = len(Xtrain[0])\n",
    "    vec_1 = np.ones(length)\n",
    "    vec_0 = np.ones(length)\n",
    "    num_1, num_0 = 2, 2\n",
    "    for i, data in enumerate(Xtrain):\n",
    "        if ytrain[i] == 1:  \n",
    "            vec_1 += data     \n",
    "            num_1 += 1  \n",
    "        else:\n",
    "            vec_0 += data\n",
    "            num_0 += 1\n",
    "    thetaPosTrue = vec_1/num_1  # 类别1的条件概率\n",
    "    thetaNegTrue = vec_0/num_0  #  类别0的条件概率\n",
    "    return thetaPosTrue, thetaNegTrue\n",
    "\n",
    "\n",
    "def naiveBayesBernFeature_test(Xtest, ytest, thetaPosTrue, thetaNegTrue):\n",
    "    yPredict = [0] * len(Xtest)\n",
    "\n",
    "    for i, test_vec in enumerate(Xtest):\n",
    "        ##################### Start For Your Code #####################\n",
    "        prob_1 = np.sum(test_vec * np.log(thetaPosTrue) + (1 - test_vec) * np.log(1 - thetaPosTrue))\n",
    "        prob_0 = np.sum(test_vec * np.log(thetaNegTrue) + (1 - test_vec) * np.log(1 - thetaNegTrue))\n",
    "\n",
    "        if prob_1 >= prob_0:\n",
    "            yPredict[i] = 1\n",
    "        else:\n",
    "            yPredict[i] = 0\n",
    "        #####################  End For Your Code  #####################\n",
    "\n",
    "    corr = 0\n",
    "    for i, label in enumerate(yPredict):\n",
    "        if label == ytest[i]:\n",
    "            corr += 1\n",
    "    Accuracy = corr / len(yPredict)\n",
    "\n",
    "    return yPredict, Accuracy\n",
    "\n",
    "\n",
    "\n",
    "thetaPosTrue, thetaNegTrue = naiveBayesBernFeature_train(train_data_bern, train_label)\n",
    "print(\"thetaPosTrue =\", thetaPosTrue)\n",
    "print(\"thetaNegTrue =\", thetaNegTrue)\n",
    "print(\"--------------------\")\n",
    "\n",
    "yPredict, Accuracy = naiveBayesBernFeature_test(test_data_bern, test_label, thetaPosTrue, thetaNegTrue)\n",
    "print(\"BNBC classification accuracy =\", Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNBC\n",
    "- 假定$P(W_1,W_2,...,W_k|C)$是一个多项式分布\n",
    "- 文档分类中的$k$维字典对应于多项式分布中的向量的$k$个维度\n",
    "$$ P(W_1=n_1,...,W_k=n_k|c,N,\\theta_{1,c},...,\\theta_{k,c})=\\frac{N!}{n_1!n_2!...n_k!}\\theta_{1,c}^{n_1}\\theta_{2,c}^{n_2}...\\theta_{k,c}^{n_k} $$\n",
    "- 其中\n",
    "$$ \\sum_{i=1}^kn_i=N, \\sum_{i=1}^k\\theta_{i,c}=1 $$ \n",
    "- $\\theta_{i,c}$对应于$w_i$在类别$c$中出现的概率，即需求出的值\n",
    "- 省略阶乘，并取对数，可以得到\n",
    "$$c=argmax\\{logP(c_j)+\\sum n_ilogp(w_i|c_j)\\}$$\n",
    "- After smoothing:\n",
    "\n",
    "$$ P(w_i|c_j)=\\frac{n_{i,j}+\\alpha}{n_j+\\alpha|vocabulary|}$$\n",
    "- 其中，$n_j$为文本$Text_j$（类别为$c_j$的文本）的长度，$n_{i,j}$为$w_i$在$Text_j$中出现的次数\n",
    "- 且$P(c=1)=P(c=0)=\\frac{1}{2}, \\alpha=1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thetaPos = [0.23350254 0.00039047 0.23428348 0.22100742 0.02030457 0.15657946\n",
      " 0.00039047 0.10542757 0.01327606 0.01366654 0.00039047 0.00039047\n",
      " 0.00039047]\n",
      "thetaNeg = [0.16808424 0.00040502 0.14661806 0.10692588 0.00526529 0.1381126\n",
      " 0.00040502 0.29040097 0.07290401 0.06966383 0.00040502 0.00040502\n",
      " 0.00040502]\n",
      "--------------------\n",
      "MNBC classification accuracy = 0.6683333333333333\n",
      "--------------------\n",
      "Sklearn MultinomialNB accuracy = 0.6683333333333333\n"
     ]
    }
   ],
   "source": [
    "########################## Question 3 ########################## \n",
    "\n",
    "#补充完整naiveBayesMulFeature_train(Xtrain, ytrain)函数\n",
    "#注意MNBC与BNBC求P(w_i|c_j)的差别即可\n",
    "\n",
    "############################################################### \n",
    "\n",
    "def naiveBayesMulFeature_train(Xtrain, ytrain):\n",
    "    length = len(Xtrain[0])\n",
    "    vec_1 = np.ones(length)\n",
    "    vec_0 = np.ones(length)\n",
    "    num_1, num_0 = length, length\n",
    "    \n",
    "    ##################### Start For Your Code ##################### \n",
    "\n",
    "    length = len(Xtrain[0])\n",
    "    vec_1 = np.ones(length)\n",
    "    vec_0 = np.ones(length)\n",
    "    num_1, num_0 = length, length\n",
    "    \n",
    "    for i, data in enumerate(Xtrain):\n",
    "        if ytrain[i] == 1:  \n",
    "            vec_1 += data     \n",
    "            num_1 += sum(data)  \n",
    "        else:\n",
    "            vec_0 += data\n",
    "            num_0 += sum(data)\n",
    "\n",
    "    #####################  End For Your Code  ##################### \n",
    "            \n",
    "    thetaPos = vec_1/num_1\n",
    "    thetaNeg = vec_0/num_0\n",
    "    return thetaPos, thetaNeg\n",
    "\n",
    "\n",
    "########################## Question 4 ########################## \n",
    "\n",
    "#利用上述公式补充完整naiveBayesMulFeature_test(Xtest, ytest,thetaPos, thetaNeg)函数\n",
    "#得到预测值和准确率\n",
    "\n",
    "############################################################### \n",
    "\n",
    "\n",
    "def naiveBayesMulFeature_test(Xtest, ytest,thetaPos, thetaNeg):    \n",
    " \n",
    "    yPredict = [0]*len(Xtest)  # 先假设样本是一个全为0的向量\n",
    "    \n",
    "    ##################### Start For Your Code ##################### \n",
    "    for i, test_vec in enumerate(Xtest):\n",
    "        pos_prob = 1\n",
    "        neg_prob = 1\n",
    "        for j, val in enumerate(test_vec):\n",
    "            pos_prob *= thetaPos[j] ** val\n",
    "            neg_prob *= thetaNeg[j] ** val\n",
    "        \n",
    "        if pos_prob > neg_prob:\n",
    "            yPredict[i] = 1\n",
    "    #####################  End For Your Code  ####################\n",
    "            \n",
    "    corr = 0\n",
    "    for i, label in enumerate(yPredict):\n",
    "        if label == ytest[i]:\n",
    "            corr = corr+1\n",
    "    Accuracy = corr/len(yPredict)    \n",
    "    return yPredict, Accuracy\n",
    "\n",
    "########################## Question 5 ########################## \n",
    "\n",
    "#直接调用sklearn.naive_bayes.MultinomialNB()进行多项式朴素贝叶斯分类\n",
    "#得到准确率\n",
    "\n",
    "############################################################### \n",
    "\n",
    "def naiveBayesMulFeature_sk_MNBC(Xtrain, ytrain, Xtest, ytest):\n",
    "    \n",
    "    ##################### Start For Your Code ##################### \n",
    "    classifier = MultinomialNB()\n",
    "    classifier.fit(Xtrain, ytrain)\n",
    "    y_pred = classifier.predict(Xtest)\n",
    "    #####################  End For Your Code  ##################### \n",
    "    \n",
    "    corr = 0\n",
    "    for i in range(0, len(y_pred)):\n",
    "        if y_pred[i] == ytest[i]:\n",
    "            corr = corr+1\n",
    "    Accuracy = corr/len(y_pred)    \n",
    "    return Accuracy\n",
    "\n",
    "\n",
    "thetaPos, thetaNeg = naiveBayesMulFeature_train(train_data, train_label)\n",
    "print(\"thetaPos =\", thetaPos)\n",
    "print(\"thetaNeg =\", thetaNeg)\n",
    "print(\"--------------------\")\n",
    "\n",
    "yPredict, Accuracy = naiveBayesMulFeature_test(test_data, test_label, thetaPos, thetaNeg)\n",
    "print(\"MNBC classification accuracy =\", Accuracy)\n",
    "print(\"--------------------\")\n",
    "\n",
    "Accuracy_sk = naiveBayesMulFeature_sk_MNBC(train_data, train_label, test_data, test_label)\n",
    "print(\"Sklearn MultinomialNB accuracy =\", Accuracy_sk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
